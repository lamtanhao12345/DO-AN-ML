{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un0Eu_AOpMIv"
   },
   "source": [
    "# I. Xử lý dữ liệu\n",
    "## Trích xuất đặc trưng của file PE. Bao gồm 69 đặc trưng:\n",
    "## Loại bỏ đặc trưng packer_type do dữ liệu không phải dạng số (vd: VC8_Microsoft_Corporation)\n",
    "\n",
    "IMAGE_DOS_HEADER (6)\n",
    "- e_cblp\n",
    "- e_cp\n",
    "- e_cparhdr\n",
    "- e_maxalloc\n",
    "- e_sp\n",
    "- e_lfanew\n",
    "\n",
    "FILE_HEADER (17)\n",
    "- NumberOfSections\n",
    "- CreationYear\n",
    "- FH_char0\n",
    "- FH_char1\n",
    "- FH_char2\n",
    "- FH_char3\n",
    "- FH_char4\n",
    "- FH_char5\n",
    "- FH_char6\n",
    "- FH_char7\n",
    "- FH_char8\n",
    "- FH_char9\n",
    "- FH_char10\n",
    "- FH_char11\n",
    "- FH_char12\n",
    "- FH_char13\n",
    "- FH_char14\n",
    "\n",
    "OPTIONAL_HEADER (37)\n",
    "- MajorLinkerVersion\n",
    "- MinorLinkerVersion\n",
    "- SizeOfCode\n",
    "- SizeOfInitializedData\n",
    "- SizeOfUninitializedData\n",
    "- AddressOfEntryPoint\n",
    "- BaseOfCode\n",
    "- BaseOfData\n",
    "- ImageBase\n",
    "- SectionAlignment\n",
    "- FileAlignment\n",
    "- MajorOperatingSystemVersion\n",
    "- MinorOperatingSystemVersion\n",
    "- MajorImageVersion\n",
    "- MinorImageVersion\n",
    "- MajorSubsystemVersion\n",
    "- MinorSubsystemVersion\n",
    "- SizeOfImage\n",
    "- SizeOfHeaders\n",
    "- CheckSum\n",
    "- Subsystem\n",
    "- OH_DLLchar0\n",
    "- OH_DLLchar1\n",
    "- OH_DLLchar2\n",
    "- OH_DLLchar3\n",
    "- OH_DLLchar4\n",
    "- OH_DLLchar5\n",
    "- OH_DLLchar6\n",
    "- OH_DLLchar7\n",
    "- OH_DLLchar8\n",
    "- OH_DLLchar9\n",
    "- OH_DLLchar10\n",
    "- SizeOfStackReserve\n",
    "- SizeOfStackCommit\n",
    "- SizeOfHeapReserve\n",
    "- SizeOfHeapCommit\n",
    "- LoaderFlags\n",
    "\n",
    "Derived Header (8)\n",
    "- sus_sections\n",
    "- non_sus_sections\n",
    "- packer\n",
    "- E_text\n",
    "- E_data\n",
    "- filesize\n",
    "- E_file\n",
    "- fileinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# II. Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Requirement already satisfied: pefile in /home/ubuntu/.local/lib/python3.8/site-packages (2024.8.26)\n",
      "Requirement already satisfied: yara in /usr/local/lib/python3.8/dist-packages/yara-1.7.7-py3.8.egg (1.7.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pefile\n",
    "!pip install yara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import pefile\n",
    "import pefile as pe\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, csv, os\n",
    "import yara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pe_features():\n",
    "\n",
    "    IMAGE_DOS_HEADER = [\n",
    "                        \"e_cblp\",\\\n",
    "                        \"e_cp\", \\\n",
    "                        \"e_cparhdr\",\\\n",
    "                        \"e_maxalloc\",\\\n",
    "                        \"e_sp\",\\\n",
    "                        \"e_lfanew\"]\n",
    "\n",
    "    FILE_HEADER= [\"NumberOfSections\",\"CreationYear\"] + [ \"FH_char\" + str(i) for i in range(15)]\n",
    "                \n",
    "\n",
    "    OPTIONAL_HEADER1 = [\n",
    "                        \"MajorLinkerVersion\",\\\n",
    "                        \"MinorLinkerVersion\",\\\n",
    "                        \"SizeOfCode\",\\\n",
    "                        \"SizeOfInitializedData\",\\\n",
    "                        \"SizeOfUninitializedData\",\\\n",
    "                        \"AddressOfEntryPoint\",\\\n",
    "                        \"BaseOfCode\",\\\n",
    "                        \"BaseOfData\",\\\n",
    "                        \"ImageBase\",\\\n",
    "                        \"SectionAlignment\",\\\n",
    "                        \"FileAlignment\",\\\n",
    "                        \"MajorOperatingSystemVersion\",\\\n",
    "                        \"MinorOperatingSystemVersion\",\\\n",
    "                        \"MajorImageVersion\",\\\n",
    "                        \"MinorImageVersion\",\\\n",
    "                        \"MajorSubsystemVersion\",\\\n",
    "                        \"MinorSubsystemVersion\",\\\n",
    "                        \"SizeOfImage\",\\\n",
    "                        \"SizeOfHeaders\",\\\n",
    "                        \"CheckSum\",\\\n",
    "                        \"Subsystem\"] \n",
    "    OPTIONAL_HEADER_DLL_char = [ \"OH_DLLchar\" + str(i) for i in range(11)]                   \n",
    "                            \n",
    "    OPTIONAL_HEADER2 = [\n",
    "                        \"SizeOfStackReserve\",\\\n",
    "                        \"SizeOfStackCommit\",\\\n",
    "                        \"SizeOfHeapReserve\",\\\n",
    "                        \"SizeOfHeapCommit\",\\\n",
    "                        \"LoaderFlags\"]  # boolean check for zero or not\n",
    "    \n",
    "    OPTIONAL_HEADER = OPTIONAL_HEADER1 + OPTIONAL_HEADER_DLL_char + OPTIONAL_HEADER2\n",
    "    Derived_header = [\"sus_sections\",\"non_sus_sections\", \"packer\",\"E_text\",\"E_data\",\"filesize\",\"E_file\",\"fileinfo\"]\n",
    "    # Derived_header = [\"sus_sections\",\"non_sus_sections\", \"packer\",\"packer_type\",\"E_text\",\"E_data\",\"filesize\",\"E_file\",\"fileinfo\"]\n",
    "    \n",
    "    def __init__(self, source, output, label):\n",
    "        self.source = source\n",
    "        self.output = output\n",
    "        self.type = label\n",
    "        self.rules= yara.compile('peid.yar')\n",
    "        \n",
    "    def file_creation_year(self,seconds):\n",
    "        tmp = 1970 + ((int(seconds) / 86400) / 365)\n",
    "        return int(tmp in range (1980,2016)) \n",
    "\n",
    "\n",
    "    def FILE_HEADER_Char_boolean_set(self,pe):\n",
    "        tmp = [pe.FILE_HEADER.IMAGE_FILE_RELOCS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_EXECUTABLE_IMAGE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LINE_NUMS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LOCAL_SYMS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_AGGRESIVE_WS_TRIM,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LARGE_ADDRESS_AWARE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_BYTES_REVERSED_LO,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_32BIT_MACHINE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_DEBUG_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_NET_RUN_FROM_SWAP,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_SYSTEM,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_DLL,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_UP_SYSTEM_ONLY,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_BYTES_REVERSED_HI\n",
    "            ]\n",
    "        return [int(s) for s in tmp]\n",
    "\n",
    "    def OPTIONAL_HEADER_DLLChar(self,pe):\n",
    "        tmp = [\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NX_COMPAT,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_ISOLATION,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_SEH,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_BIND,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_WDM_DRIVER,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_APPCONTAINER,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_GUARD_CF\n",
    "            ]\n",
    "        return [int(s) for s in tmp]\n",
    "    def Optional_header_ImageBase(self,ImageBase):\n",
    "        result= 0\n",
    "        if ImageBase % (64 * 1024) == 0 and ImageBase in [268435456,65536,4194304]:\n",
    "            result = 1\n",
    "        return result\n",
    "    def Optional_header_SectionAlignment(self,SectionAlignment,FileAlignment):\n",
    "        \"\"\"This is boolean function and will return 0 or 1 based on condidtions\n",
    "        that it SectionAlignment must be greater than or equal to FileAlignment\n",
    "        \"\"\"\n",
    "        return int(SectionAlignment >= FileAlignment)\n",
    "    def Optional_header_FileAlignment(self,SectionAlignment,FileAlignment):\n",
    "        result =0\n",
    "        if SectionAlignment >= 512:\n",
    "            if FileAlignment % 2 == 0 and FileAlignment in range(512,65537):\n",
    "                result =1\n",
    "        else: \n",
    "            if FileAlignment == SectionAlignment:\n",
    "                result = 1\n",
    "        return result\n",
    "\n",
    "    def Optional_header_SizeOfImage(self,SizeOfImage,SectionAlignment):\n",
    "        return int(SizeOfImage % SectionAlignment == 0)\n",
    "\n",
    "    def Optional_header_SizeOfHeaders(self,SizeOfHeaders,FileAlignment):\n",
    "        return int(SizeOfHeaders % FileAlignment == 0 )\n",
    "\n",
    "\n",
    "    def extract_dos_header(self,pe):\n",
    "        IMAGE_DOS_HEADER_data = [ 0 for i in range(6)]\n",
    "        try:\n",
    "            IMAGE_DOS_HEADER_data = [\n",
    "                                pe.DOS_HEADER.e_cblp,\\\n",
    "                                pe.DOS_HEADER.e_cp, \\\n",
    "                                pe.DOS_HEADER.e_cparhdr,\\\n",
    "                                pe.DOS_HEADER.e_maxalloc,\\\n",
    "                                pe.DOS_HEADER.e_sp,\\\n",
    "                                pe.DOS_HEADER.e_lfanew]\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "        return IMAGE_DOS_HEADER_data\n",
    "\n",
    "    def extract_file_header(self,pe):\t\n",
    "        FILE_HEADER_data = [ 0 for i in range(3)]\n",
    "        FILE_HEADER_char =  []\n",
    "        try:\n",
    "            FILE_HEADER_data = [ \n",
    "                    pe.FILE_HEADER.NumberOfSections, \\\n",
    "                    self.file_creation_year(pe.FILE_HEADER.TimeDateStamp)]\n",
    "            FILE_HEADER_char = self.FILE_HEADER_Char_boolean_set(pe)\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "        return FILE_HEADER_data + FILE_HEADER_char\n",
    "\n",
    "    def extract_optional_header(self,pe):\n",
    "        OPTIONAL_HEADER_data = [ 0 for i in range(21)]\n",
    "        DLL_char =[]\n",
    "        OPTIONAL_HEADER_data2 = [ 0 for i in range(6)]\n",
    "\n",
    "        try:\n",
    "            OPTIONAL_HEADER_data = [\n",
    "                pe.OPTIONAL_HEADER.MajorLinkerVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorLinkerVersion,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfCode,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfInitializedData,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfUninitializedData,\\\n",
    "                pe.OPTIONAL_HEADER.AddressOfEntryPoint,\\\n",
    "                pe.OPTIONAL_HEADER.BaseOfCode,\\\n",
    "                pe.OPTIONAL_HEADER.BaseOfData,\\\n",
    "                #Check the ImageBase for the condition\n",
    "                self.Optional_header_ImageBase(pe.OPTIONAL_HEADER.ImageBase),\\\n",
    "                # Checking for SectionAlignment condition\n",
    "                self.Optional_header_SectionAlignment(pe.OPTIONAL_HEADER.SectionAlignment,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                #Checking for FileAlignment condition\n",
    "                self.Optional_header_FileAlignment(pe.OPTIONAL_HEADER.SectionAlignment,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MajorImageVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorImageVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MajorSubsystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorSubsystemVersion,\\\n",
    "                #Checking size of Image\n",
    "                self.Optional_header_SizeOfImage(pe.OPTIONAL_HEADER.SizeOfImage,pe.OPTIONAL_HEADER.SectionAlignment),\\\n",
    "                #Checking for size of headers\n",
    "                self.Optional_header_SizeOfHeaders(pe.OPTIONAL_HEADER.SizeOfHeaders,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                pe.OPTIONAL_HEADER.CheckSum,\\\n",
    "                pe.OPTIONAL_HEADER.Subsystem]\n",
    "\n",
    "            DLL_char = self.OPTIONAL_HEADER_DLLChar(pe)\n",
    "\n",
    "            OPTIONAL_HEADER_data2= [                \n",
    "                pe.OPTIONAL_HEADER.SizeOfStackReserve,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfStackCommit,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfHeapReserve,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfHeapCommit,\\\n",
    "                int(pe.OPTIONAL_HEADER.LoaderFlags == 0) ]\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "        return OPTIONAL_HEADER_data + DLL_char + OPTIONAL_HEADER_data2\n",
    "\n",
    "    def get_count_suspicious_sections(self,pe):\n",
    "        result=[]\n",
    "        tmp =[]\n",
    "        benign_sections = set(['.text','.data','.rdata','.idata','.edata','.rsrc','.bss','.crt','.tls'])\n",
    "        for section in pe.sections:\n",
    "            tmp.append(section.Name.split(b'\\x00')[0])\n",
    "        non_sus_sections = len(set(tmp).intersection(benign_sections))\n",
    "        result=[len(tmp) - non_sus_sections, non_sus_sections]\n",
    "        return result\n",
    "\n",
    "\n",
    "    def check_packer(self,filepath):\n",
    "        result=[]\n",
    "        matches = self.rules.match(filepath)\n",
    "        if matches == []:\n",
    "            result.append([0,\"NoPacker\"])\n",
    "        else:\n",
    "            #result.append([1,matches['main'][0]['rule']])\n",
    "            result.append([1,matches[0]])\n",
    "        return result\n",
    "\n",
    "    def get_text_data_entropy(self,pe):\n",
    "        result=[0.0,0.0]\n",
    "        for section in pe.sections:\n",
    "            s_name = section.Name.split(b'\\x00')[0]\n",
    "            if s_name == \".text\":\n",
    "                result[0]= section.get_entropy()\n",
    "            elif s_name == \".data\":\n",
    "                result[1]= section.get_entropy()\n",
    "            else:\n",
    "                pass\n",
    "        return result  \n",
    "\n",
    "    def get_file_bytes_size(self,filepath):\n",
    "        f = open(filepath, \"rb\")\n",
    "        data = f.read()\n",
    "        # byteArr = [ord(c) for c in f.read()]\n",
    "        #f.close()\n",
    "        fileSize = len(data)\n",
    "        return data, fileSize\n",
    "\n",
    "    def cal_byteFrequency(self,byteArr,fileSize):\n",
    "        freqList = []\n",
    "        for b in range(256):\n",
    "            ctr = 0\n",
    "            for byte in byteArr:\n",
    "                if byte == b:\n",
    "                    ctr += 1\n",
    "            freqList.append(float(ctr) / fileSize)\n",
    "        return freqList\n",
    "\n",
    "    def get_file_entropy(self,filepath):\n",
    "        byteArr, fileSize = self.get_file_bytes_size(filepath)\n",
    "        freqList = self.cal_byteFrequency(byteArr,fileSize)\n",
    "        # Shannon entropy\n",
    "        ent = 0.0\n",
    "        for freq in freqList:\n",
    "            if freq > 0:\n",
    "                ent +=  - freq * math.log(freq, 2)\n",
    "\n",
    "            #ent = -ent\n",
    "        return [fileSize,ent]\n",
    "    \n",
    "    def get_fileinfo(self,pe):\n",
    "        result=[]\n",
    "        try:\n",
    "            FileVersion    = pe.FileInfo[0].StringTable[0].entries['FileVersion']\n",
    "            ProductVersion = pe.FileInfo[0].StringTable[0].entries['ProductVersion']\n",
    "            ProductName =    pe.FileInfo[0].StringTable[0].entries['ProductName']\n",
    "            CompanyName = pe.FileInfo[0].StringTable[0].entries['CompanyName']\n",
    "    #getting Lower and \n",
    "            FileVersionLS    = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "            FileVersionMS    = pe.VS_FIXEDFILEINFO.FileVersionMS\n",
    "            ProductVersionLS = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "            ProductVersionMS = pe.VS_FIXEDFILEINFO.ProductVersionMS\n",
    "        except Exception as e:\n",
    "            result=[\"error\"]\n",
    "        #print \"{} while opening {}\".format(e,filepath)\n",
    "        else:\n",
    "    #shifting byte\n",
    "            FileVersion = (FileVersionMS >> 16, FileVersionMS & 0xFFFF, FileVersionLS >> 16, FileVersionLS & 0xFFFF)\n",
    "            ProductVersion = (ProductVersionMS >> 16, ProductVersionMS & 0xFFFF, ProductVersionLS >> 16, ProductVersionLS & 0xFFFF)\n",
    "            result = [FileVersion,ProductVersion,ProductName,CompanyName]\n",
    "        return int ( result[0] != 'error')\n",
    "\n",
    "    def write_csv_header(self):\n",
    "        if os.path.exists(self.output): return\n",
    "        filepath = self.output\n",
    "        header= self.IMAGE_DOS_HEADER + self.FILE_HEADER + self.OPTIONAL_HEADER + self.Derived_header\n",
    "        header.append(\"class\")\n",
    "        csv_file= open(filepath,\"a\")\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        csv_file.close()\n",
    "\n",
    "    def extract_all(self,filepath):\n",
    "        data =[]\n",
    "\n",
    "\n",
    "        os.system(f'cp {filepath} /tmp/1.exe')\n",
    "        filepath = '/tmp/1.exe'\n",
    "\n",
    "        try:\n",
    "            pe = pefile.PE(filepath)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            data += self.extract_dos_header(pe)\n",
    "        except Exception as err:\n",
    "            print('ERROR EXTRACT DOS HEADER: ' + str(err))\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            data += self.extract_file_header(pe)\n",
    "        except Exception as err:\n",
    "            print('ERROR EXTRACT FILE HEADER: ' + str(err))\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            data += self.extract_optional_header(pe)\n",
    "        except Exception as err:\n",
    "            print('ERROR EXTRACT OPTIONAL HEADER: ' + str(err))\n",
    "            return None\n",
    "            \n",
    "            # derived features\n",
    "            #number of suspicisou sections and non-suspicsious section\n",
    "        try:\n",
    "            num_ss_nss = self.get_count_suspicious_sections(pe)\n",
    "            data += num_ss_nss\n",
    "        except Exception as err:\n",
    "            print('ERROR get_count_suspicious_sections: ' + str(err))\n",
    "            return None\n",
    "\n",
    "        # try:\n",
    "        #     packer = self.check_packer(filepath)\n",
    "        #     data += packer[0]\n",
    "        # except Exception as err:\n",
    "        #     print('ERROR check packer: ' + str(err))\n",
    "        #     return None\n",
    "\n",
    "        try:\n",
    "            entropy_sections = self.get_text_data_entropy(pe)\n",
    "            data += entropy_sections\n",
    "        except Exception as err:\n",
    "            print('ERROR check entropy: ' + str(err))\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            f_size_entropy = self.get_file_entropy(filepath)\n",
    "            data += f_size_entropy\n",
    "        except Exception as err:\n",
    "            print('ERROR check fsize entropy: ' + str(err))\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            fileinfo = self.get_fileinfo(pe)\n",
    "            data.append(fileinfo)\n",
    "            data.append(self.type)\n",
    "        except Exception as err:\n",
    "            print('ERROR check fileinfo: ' + str(err))\n",
    "            return None\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def write_csv_data(self,data):\n",
    "        filepath = self.output\n",
    "        csv_file= open(filepath,\"a\")\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(data)\n",
    "        csv_file.close()\n",
    "    \n",
    "\n",
    "    def create_dataset(self):\n",
    "        self.write_csv_header()\n",
    "        #run through all file of source and extract features\n",
    "\n",
    "        count = 0\n",
    "        files = os.listdir(self.source)\n",
    "        lenfile = len(files)\n",
    "        for file in files:         \n",
    "                print(\"Extract: {} / {}\".format(count, lenfile))\n",
    "                count += 1\n",
    "                filepath = self.source + file\n",
    "                data = self.extract_all(filepath)\n",
    "                print(data)\n",
    "                if data != None and len(data)>0:\n",
    "                    self.write_csv_data(data)\n",
    "                    print(\"Successfully Data extracted and written for {}.\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract: 0 / 2334\n",
      "[144, 3, 4, 65535, 184, 256, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 14, 16, 81408, 27136, 0, 30941, 4096, 86016, 1, 1, 1, 5, 1, 0, 0, 5, 1, 1, 1, 164418, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1048576, 4096, 1048576, 4096, 1, 5, 0, 0.0, 0.0, 116880, 6.524627405101686, 0, '0']\n",
      "Successfully Data extracted and written for 001405CE2F3363F6C22585D152A14969.exe.\n",
      "Extract: 1 / 2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f78fc78f580>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m PE_EXTRACTOR \u001b[38;5;241m=\u001b[39m pe_features(source\u001b[38;5;241m=\u001b[39mPATH_BENIGN, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mPE_EXTRACTOR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# PE_EXTRACTOR = pe_features(source=PATH_MALWARE, output='dataset.csv', label=\"1\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# PE_EXTRACTOR.create_dataset()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 381\u001b[0m, in \u001b[0;36mpe_features.create_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    380\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m+\u001b[39m file\n\u001b[0;32m--> 381\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 346\u001b[0m, in \u001b[0;36mpe_features.extract_all\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     f_size_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f_size_entropy\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "Cell \u001b[0;32mIn[4], line 249\u001b[0m, in \u001b[0;36mpe_features.get_file_entropy\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_file_entropy\u001b[39m(\u001b[38;5;28mself\u001b[39m,filepath):\n\u001b[1;32m    248\u001b[0m     byteArr, fileSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_file_bytes_size(filepath)\n\u001b[0;32m--> 249\u001b[0m     freqList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_byteFrequency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyteArr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfileSize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Shannon entropy\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     ent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 242\u001b[0m, in \u001b[0;36mpe_features.cal_byteFrequency\u001b[0;34m(self, byteArr, fileSize)\u001b[0m\n\u001b[1;32m    240\u001b[0m ctr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m byte \u001b[38;5;129;01min\u001b[39;00m byteArr:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbyte\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m:\n\u001b[1;32m    243\u001b[0m         ctr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    244\u001b[0m freqList\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(ctr) \u001b[38;5;241m/\u001b[39m fileSize)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH_BENIGN = './Dataset/files/benign/'\n",
    "PATH_MALWARE = './Dataset/files/malware/'\n",
    "PATH_BENIGN = '/mnt/hgfs/dataset/'\n",
    "\n",
    "import os\n",
    "\n",
    "PE_EXTRACTOR = pe_features(source=PATH_BENIGN, output='new.csv', label=\"0\")\n",
    "PE_EXTRACTOR.create_dataset()\n",
    "\n",
    "# PE_EXTRACTOR = pe_features(source=PATH_MALWARE, output='dataset.csv', label=\"1\")\n",
    "# PE_EXTRACTOR.create_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPOjdRlXIYLFqO4293smHCX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
